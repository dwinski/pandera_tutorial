{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78cbd31",
   "metadata": {},
   "source": [
    "# A Brief Intro to Data Validation in Python with Pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27c7c4",
   "metadata": {},
   "source": [
    "## What is Data Validation?\n",
    "\n",
    "- Verifying that data is appropriate for analysis\n",
    "  - correct format?\n",
    "  - right data types?\n",
    "  - unique, no duplicates?\n",
    "  - missing values?\n",
    "  - data in expected range?\n",
    "- Particularly important to automate in situations where you are ingesting new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d1ac5",
   "metadata": {},
   "source": [
    "## Pandera: Data Validation Package for Python\n",
    "\n",
    "- https://pandera.readthedocs.io/en/latest/index.html#\n",
    "- Data validation package designed to work with dataframes\n",
    "- Checks data in dataframes against schema (set of rules) \n",
    "- Schema (DataFrameSchema object) contains suite of tests that you specify\n",
    "- You test data in dataframe against schema to see if it conforms to expectations\n",
    "- Can be used with dataframes from:\n",
    "  - pandas\n",
    "  - polars\n",
    "  - PySpark SQL\n",
    "- A lot of functionality, we'll just cover basics here\n",
    "- \"validate\" package for R is similar:\n",
    "  - https://cran.r-project.org/web/packages/validate/vignettes/cookbook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0424d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed packages/classes/functions\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import Column, DataFrameSchema, Check, check_input, check_output, check_io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa56dd",
   "metadata": {},
   "source": [
    "### We'll use the Titanic Dataset for this Brief Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in titanic dataset \n",
    "df = pd.read_csv('../datasets/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d940816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse df\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types of df\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2615c7",
   "metadata": {},
   "source": [
    "## We'll Create a simple DataFrameSchema for the Titanic Dataset\n",
    "\n",
    "### We'll use these datatypes:\n",
    "\n",
    "- survived: int\n",
    "- pclass: int\n",
    "- name: str\n",
    "- sex: str\n",
    "- age: float\n",
    "- fare: float\n",
    "- sibsp: int\n",
    "- parch: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to create simple DataFrameSchema for titanic dataset\n",
    "def create_titanic_schema() -> DataFrameSchema:\n",
    "    \"\"\"Creates simple pandera DataFrameSchema for titanic dataset\"\"\"\n",
    "    \n",
    "    schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int),\n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "    \n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the titanic schema\n",
    "schema = create_titanic_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!') # just to give us an affirmative output\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654ca4f",
   "metadata": {},
   "source": [
    "## Column-Level Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba6709",
   "metadata": {},
   "source": [
    "### Testing for Presence/Absence of Columns\n",
    "- required = True (default)\n",
    "- required = False (allows absence of column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, all columns specified by schema are required\n",
    "# implicit 'required = True'\n",
    "# dropping a column raises error\n",
    "\n",
    "try:\n",
    "    schema.validate(df.drop('survived', axis = 1))\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using required=False within  \n",
    "# column definition makes it optional\n",
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int, required=False),\n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737136d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after change to schema, we can validate the dataframe with missing column\n",
    "\n",
    "try:\n",
    "    schema.validate(df.drop('survived', axis = 1))\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd51f55",
   "metadata": {},
   "source": [
    "### Testing for Data Type of Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da19c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I change the data type of the age column to str \n",
    "# and try to validate the df with our schema?\n",
    "df['age'] = df['age'].astype(str)\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e681a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's revert the data type of pclass to be int as expected by schema\n",
    "df['age'] = df['age'].astype(float)\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f95fa9",
   "metadata": {},
   "source": [
    "### Testing for Null Values in Column\n",
    "- by default, columns are non-nullable\n",
    "- Can change this for given column in column definition \n",
    "  - nullable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5439e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show there are no null values in df\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, null values won't validate\n",
    "# let's create a null value to demonstrate this\n",
    "\n",
    "df.loc[0, 'age'] = None\n",
    "df['age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of nullable = True\n",
    "# allows null values in column to pass validation\n",
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int),\n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float, nullable=True),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing back to original value\n",
    "df.loc[0, 'age'] = 22.0\n",
    "df['age'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602feca0",
   "metadata": {},
   "source": [
    "### Testing for Duplicates in a Column\n",
    "- by default, duplicate values within a column are allowed\n",
    "- Can raise error when duplicate values appear in column:\n",
    "  - unique = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bffc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float, unique=True),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283741dc",
   "metadata": {},
   "source": [
    "### Testing that Values Are Greater Than/Less Than Specific Value\n",
    "- Check.greater_than()\n",
    "- Check.greater_than_or_equal_to()\n",
    "- Check.less_than()\n",
    "- Check.less_than_or_equal_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float, Check.greater_than(0)),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b8954",
   "metadata": {},
   "source": [
    "### Testing that Values Are In a Specific Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float, Check.between(0, 125, include_min=True, include_max=True)),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc53533",
   "metadata": {},
   "source": [
    "### Testing that Values in Column are Members of Specified Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int, Check.isin([1, 2, 3])),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab687767",
   "metadata": {},
   "source": [
    "### Tests on Column of Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might want to check that names contain a title\n",
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str, Check.str_contains('Mr|Mrs|Ms|Miss|Master|Dr|Rev')),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291008f",
   "metadata": {},
   "source": [
    "### Create Custom Tests \n",
    "- Can use lambda functions to create custom column checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float, Check(lambda x: (x >= 0) & (x < 500), \n",
    "                                                        error = \"fare out of bounds\")\n",
    "                                            ),  # same as Check.between()\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom function to use as column check in DataFrameSchema\n",
    "def within_3_std(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Check if values in col are within 3 sds of mean of col\"\"\"\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    lower_bound = mean - 3*std\n",
    "    upper_bound = mean + 3*std\n",
    "    return series.between(lower_bound, upper_bound)\n",
    "\n",
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float, Check(within_3_std)),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49bdcf7",
   "metadata": {},
   "source": [
    "- Tests can also involve multiple columns in single test\n",
    "- These are really dataframe-level tests\n",
    "  - Use lambda functions on whole df (below the column dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b83c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema dataframe-level check across cols\n",
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            },\n",
    "                            Check(lambda df: (df[\"sibsp\"] + df[\"parch\"] <= 10),\n",
    "                            error=\"Family size (sibsp + parch) is too large\")\n",
    "                        )\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b1aff",
   "metadata": {},
   "source": [
    "### More Sophisticated Tests on Columns are Possible\n",
    "\n",
    "- Can use hypothesis and scipy packages for statistical tests\n",
    "  - Useful for detecting data drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d72ce",
   "metadata": {},
   "source": [
    "## Dataframe-Level Tests\n",
    "- Tests that apply to all columns/rows of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e9652",
   "metadata": {},
   "source": [
    "### Testing Presence/Absence of All Columns\n",
    "\n",
    "- Columns not specified in schema aren't check\n",
    "- Can add tests at dataframe level to check for presence/absence of columns\n",
    "  - strict = True\n",
    "  - Only columns listed in schema can be present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ed8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column not in our schema\n",
    "df['is_child'] = df['age'] < 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e36ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to validate with new column (should validate successfully)\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add strict=True to schema\n",
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            },\n",
    "                            strict=True\n",
    "                        )\n",
    "\n",
    "# with strict = True, won't validate with unspecified column\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git rid of column not in schema\n",
    "df = df.drop('is_child', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30475d7",
   "metadata": {},
   "source": [
    "### Testing Order of Cols\n",
    "\n",
    "- Used for enforcing column order specified in schema\n",
    "  - ordered = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e130529",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            },\n",
    "                            ordered = True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change order of columns\n",
    "# 'survived' col becomes last column\n",
    "df = df[['pclass',\n",
    "        'name',\n",
    "        'sex',\n",
    "        'age',\n",
    "        'fare',\n",
    "        'sibsp',\n",
    "        'parch',\n",
    "        'survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ordered = True, new order of cols won't validate\n",
    "try:\n",
    "    schema.validate(df)\n",
    "    print('Validated!')\n",
    "except pa.errors.SchemaError as schema_error:\n",
    "    print(schema_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a0ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change order of columns\n",
    "# back to match schema\n",
    "df = df[['survived',\n",
    "        'pclass',\n",
    "        'name',\n",
    "        'sex',\n",
    "        'age',\n",
    "        'fare',\n",
    "        'sibsp',\n",
    "        'parch']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab388a1",
   "metadata": {},
   "source": [
    "### Testing Uniqueness of Sets of Columns\n",
    "- To make sure you don't have columns with duplicate values\n",
    "- unique = [\"col_1\", \"col_2\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5ef86",
   "metadata": {},
   "source": [
    "## Pandera can attempt to infer a schema automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have pandera automatically infer the DataFrameSchema from the dataframe\n",
    "schema_inferred = pa.infer_schema(df)\n",
    "\n",
    "# inspect schema\n",
    "print(schema_inferred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7402a32",
   "metadata": {},
   "source": [
    "## Lazy Validation \n",
    "- Lazy Validation\n",
    "  - Typically, you'll have many tests you want to perform on a dataframe\n",
    "  - By default, the first failed test raises an error\n",
    "  - Can set lazy=True in validate function to accumulate results of all tests and see all errors that have occurred\n",
    "  - schema.validate(df, lazy=True)\n",
    "  - Easiest to view accumulated results as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942826fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int, Check.isin([2, 3])),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float, Check.between(5, 65, include_min=True, include_max=True)),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "# toggle between lazy=False and lazy=True to see difference\n",
    "try:\n",
    "    schema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    print(json.dumps(e.message, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e0b14",
   "metadata": {},
   "source": [
    "## Generating Error Reports\n",
    "- Can write error reports to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = DataFrameSchema(\n",
    "                            {\"survived\": Column(int), \n",
    "                             \"pclass\": Column(int, Check.isin([2, 3])),\n",
    "                             \"name\": Column(str),\n",
    "                             \"sex\": Column(str),\n",
    "                             \"age\": Column(float, Check.between(5, 65, include_min=True, include_max=True)),\n",
    "                             \"fare\": Column(float),\n",
    "                             \"sibsp\": Column(int),\n",
    "                             \"parch\": Column(int)\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "\n",
    "try:\n",
    "    schema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    json_string = json.dumps(e.message, indent=2)\n",
    "    print(json_string)\n",
    "\n",
    "with open(\"../schema_error_reports/schema_error_log.json\", \"w\") as file:\n",
    "    file.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffdf46a",
   "metadata": {},
   "source": [
    "## Schema Transformations\n",
    "- Can be used to modify schemas without needing to redefine entire schema\n",
    "  - schema.add_columns()\n",
    "  - schema.remove_columns()\n",
    "  - schema.update_columns()\n",
    "  - schema.rename_columns()\n",
    "  - schema.set_index()\n",
    "  - schema.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5778d14",
   "metadata": {},
   "source": [
    "## Saving Schema Specifications\n",
    "- Schema specifications can be saved to file\n",
    "  - .py \n",
    "  - .yaml Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing schema specification as python script\n",
    "schema.to_script('../schemas/titanic_schema.py')\n",
    "\n",
    "# storing schema specification as yaml file\n",
    "schema.to_yaml('../schemas/titanic_schema.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read schema from yaml\n",
    "\n",
    "schema_from_yaml = pa.io.from_yaml('../schemas/titanic_schema.yaml')\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00253a7",
   "metadata": {},
   "source": [
    "## Using Pandera decorators for integration of data validation into data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb70c96",
   "metadata": {},
   "source": [
    "### What's a decorator?\n",
    "- a function (higher-order function) that modifies the behavior of a function without direct changing the code in the function or class\n",
    "- essentially a wrapper that can be used to extend/alter original function\n",
    "- denoted in python by the @ symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ebbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not execute code in this cell, just for understanding\n",
    "\n",
    "# toy example of what a decorated function looks like\n",
    "@my_decorator\n",
    "def my_function():\n",
    "    pass\n",
    "\n",
    "# behind the scenes, the function is modified by the decorator\n",
    "# decorator takes the function as argument\n",
    "def my_function():\n",
    "    pass\n",
    "my_function = my_decorator(my_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893c362",
   "metadata": {},
   "source": [
    "### Pandera Decorators for Integrating Validation Into Data Pipeline Functions\n",
    "- @check_input\n",
    "- @check_output\n",
    "- @check_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_family_size(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute passenger family size as sum of sibsp + parch\n",
    "    and append this sum to df as new 'family_size' column\"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df['family_size'] = df['sibsp'] + df['parch']\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868998d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input schema for example\n",
    "titanic_input_schema = create_titanic_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output schema for example\n",
    "titanic_output_schema = titanic_input_schema.add_columns({\"family_size\": Column(int),\n",
    "                                                          \"can_swim\": Column(int)})\n",
    "\n",
    "print(titanic_output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function with validation decorator\n",
    "# toggle between\n",
    "# @check_input(titanic_input_schema) and @check_output(titanic_output_schema)\n",
    "@check_input(titanic_input_schema)\n",
    "def compute_family_size(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute passenger family size as sum of sibsp + parch\n",
    "    and append this sum to df as new 'family_size' column\"\"\"\n",
    "\n",
    "    df = df.copy() \n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate inputs/outputs and add computed family size to df \n",
    "df_out = compute_family_size(df)\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @check_io needs schemas associated with both input df(s) and output df\n",
    "@check_io(df=titanic_input_schema, out=titanic_output_schema)\n",
    "def compute_family_size(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute passenger family size as sum of sibsp + parch\n",
    "    and append this sum to df as new 'family_size' column\"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df['family_size'] = df['sibsp'] + df['parch']\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# won't validate due to 'can_swim' column\n",
    "# being expected in output schema\n",
    "df_out = compute_family_size(df)\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecc4d4",
   "metadata": {},
   "source": [
    "## The End! Thanks for your attention!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
